# from sklearn.metrics import mean_absolute_error,mean_squared_error,r2_score
# y_test=[3,4,5,6]
# y_pred=[2.8,4.2,5.1,6.2]
# mae=mean_absolute_error(y_test,y_pred)
# mse=mean_squared_error(y_test,y_pred)
# r2=r2_score(y_test,y_pred)
# print(f"{mae},{mse},{r2}")
# from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix

# # Actual and predicted labels
# y_test = [0, 1, 1, 0, 1]
# y_pred = [0, 1, 0, 0, 1]

# accuracy = accuracy_score(y_test, y_pred)
# precision = precision_score(y_test, y_pred)
# recall = recall_score(y_test, y_pred)
# f1 = f1_score(y_test, y_pred)
# cm = confusion_matrix(y_test, y_pred)

# print(f"Accuracy: {accuracy}")
# print(f"Precision: {precision}")
# print(f"Recall: {recall}")
# print(f"F1-Score: {f1}")
# print(f"Confusion Matrix:\n{cm}")

